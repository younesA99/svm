{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/M4dJljkHiY07iTiZ2YI+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younesA99/svm/blob/main/Untitled16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B_48Gv6IXjfc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder  # For handling categorical features if needed\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "dataset=pd.read_excel(\"Concrete_Data.xls\")\n",
        "#dataset.head()"
      ],
      "metadata": {
        "id": "4oKrDTWkYIgj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#renaming all featurses\n",
        "dataset.columns = ['cement','blastFurnace','flyAsh','water','superplasticizer','courseAggregate','fineaggregate','age','strength']\n",
        "#dataset.head()"
      ],
      "metadata": {
        "id": "8tqjRjw6YLT4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset.drop('strength', axis=1)  # Features (independent variables)\n",
        "y = dataset['strength']  # Target variable (dependent variable)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aZms1lVXYUWd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# Division des données en ensembles d'entraînement et de test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modèles\n",
        "models = {\n",
        "    'DT': DecisionTreeRegressor(),\n",
        "    'KNN': KNeighborsRegressor(),\n",
        "    'ANN': MLPRegressor(max_iter=2000),  # Increase max_iter for convergence\n",
        "    'SVR': SVR(),\n",
        "    'RF': RandomForestRegressor()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Entraînement du modèle\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Prédiction sur l'ensemble d'entraînement\n",
        "    y_train_pred = model.predict(x_train)\n",
        "\n",
        "    # Prédiction sur l'ensemble de test\n",
        "    y_test_pred = model.predict(x_test)\n",
        "\n",
        "    # Évaluation de la performance\n",
        "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Modèle: {name}\")\n",
        "    print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "    print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9stWgM2YgjC",
        "outputId": "a5fecbbd-d66e-4323-a4e1-561244534cbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle: DT\n",
            "Ensemble d'entraînement - MAE: 0.05761212685613912 RMSE: 0.8356796417488699 R²: 0.9975417004090303\n",
            "Ensemble de test - MAE: 4.678313169470253 RMSE: 7.442044382069549 R²: 0.785067561634438\n",
            "\n",
            "Modèle: KNN\n",
            "Ensemble d'entraînement - MAE: 5.491303200545663 RMSE: 7.1499237136484695 R²: 0.8200474602277927\n",
            "Ensemble de test - MAE: 6.856961032385598 RMSE: 8.62120108773313 R²: 0.7115616487614582\n",
            "\n",
            "Modèle: ANN\n",
            "Ensemble d'entraînement - MAE: 3.094795581092953 RMSE: 4.1168473133266374 R²: 0.9403398028178724\n",
            "Ensemble de test - MAE: 4.139677811555522 RMSE: 5.499204416913051 R²: 0.882640788880917\n",
            "\n",
            "Modèle: SVR\n",
            "Ensemble d'entraînement - MAE: 7.314187963311093 RMSE: 9.57538606552776 R²: 0.6772488855961507\n",
            "Ensemble de test - MAE: 7.566768476725256 RMSE: 9.52397767283592 R²: 0.64799065626556\n",
            "\n",
            "Modèle: RF\n",
            "Ensemble d'entraînement - MAE: 1.2951449326066007 RMSE: 1.965750620686839 R²: 0.9863977107060531\n",
            "Ensemble de test - MAE: 3.885375873630898 RMSE: 5.6368947164523915 R²: 0.8766902830183576\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalisation des données avec MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# Division des données en ensembles d'entraînement et de test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modèles\n",
        "models = {\n",
        "    'DT': DecisionTreeRegressor(),\n",
        "    'KNN': KNeighborsRegressor(),\n",
        "    'ANN': MLPRegressor(max_iter=3000),  # Increase max_iter for convergence\n",
        "    'SVR': SVR(),\n",
        "    'RF': RandomForestRegressor()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Entraînement du modèle\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Prédiction sur l'ensemble d'entraînement\n",
        "    y_train_pred = model.predict(x_train)\n",
        "\n",
        "    # Prédiction sur l'ensemble de test\n",
        "    y_test_pred = model.predict(x_test)\n",
        "\n",
        "    # Évaluation de la performance\n",
        "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Modèle: {name}\")\n",
        "    print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "    print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQyWiVIOZIjk",
        "outputId": "18cb4583-949f-48a9-c8fc-f96b50a0bca9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle: DT\n",
            "Ensemble d'entraînement - MAE: 0.05761212685613912 RMSE: 0.8356796417488699 R²: 0.9975417004090303\n",
            "Ensemble de test - MAE: 4.322108447256661 RMSE: 6.886529464857268 R²: 0.8159574362978357\n",
            "\n",
            "Modèle: KNN\n",
            "Ensemble d'entraînement - MAE: 5.644156419799942 RMSE: 7.433414818420611 R²: 0.8054944927733517\n",
            "Ensemble de test - MAE: 6.980557781553479 RMSE: 9.015645154856017 R²: 0.6845641325113896\n",
            "\n",
            "Modèle: ANN\n",
            "Ensemble d'entraînement - MAE: 4.876709718568761 RMSE: 6.500219646076626 R²: 0.8512656676999953\n",
            "Ensemble de test - MAE: 5.207124658602894 RMSE: 6.5667371120431515 R²: 0.8326534686046239\n",
            "\n",
            "Modèle: SVR\n",
            "Ensemble d'entraînement - MAE: 7.995771883962952 RMSE: 10.245435905406593 R²: 0.6304986361212028\n",
            "Ensemble de test - MAE: 8.097910927692936 RMSE: 10.06742570822657 R²: 0.6066724914101391\n",
            "\n",
            "Modèle: RF\n",
            "Ensemble d'entraînement - MAE: 1.305881034286101 RMSE: 1.9945061696220305 R²: 0.9859968438277052\n",
            "Ensemble de test - MAE: 3.9255096994187775 RMSE: 5.701347573954959 R²: 0.8738542886499732\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Définition des hyperparamètres à optimiser\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialisation du modèle DecisionTreeRegressor\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Initialisation de GridSearchCV avec le modèle et les hyperparamètres à optimiser\n",
        "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Entraînement du modèle avec GridSearchCV\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs paramètres et du meilleur score\n",
        "print(\"Meilleurs paramètres trouvés :\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Meilleur score (RMSE) :\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "# Utilisation du meilleur modèle pour les prédictions\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "y_train_pred = best_dt_model.predict(x_train)\n",
        "y_test_pred = best_dt_model.predict(x_test)\n",
        "\n",
        "# Évaluation de la performance sur les ensembles d'entraînement et de test\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nPerformance du meilleur modèle (Decision Tree) :\")\n",
        "print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k79FSaZYfYgX",
        "outputId": "9f4482eb-4ec7-4654-d0a0-bfc7cfd2bf23"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
            "Meilleurs paramètres trouvés :\n",
            "{'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "Meilleur score (RMSE) : 7.081986304948886\n",
            "\n",
            "Performance du meilleur modèle (Decision Tree) :\n",
            "Ensemble d'entraînement - MAE: 1.118828053458724 RMSE: 1.923926637241884 R²: 0.9869703671155198\n",
            "Ensemble de test - MAE: 4.439402722796468 RMSE: 6.694227594864658 R²: 0.8260924640479093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Définition des hyperparamètres à optimiser\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "}\n",
        "\n",
        "# Initialisation du modèle KNeighborsRegressor\n",
        "knn_model = KNeighborsRegressor()\n",
        "\n",
        "# Initialisation de GridSearchCV avec le modèle et les hyperparamètres à optimiser\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Entraînement du modèle avec GridSearchCV\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs paramètres et du meilleur score\n",
        "print(\"Meilleurs paramètres trouvés :\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Meilleur score (RMSE) :\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "# Utilisation du meilleur modèle pour les prédictions\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "y_train_pred = best_knn_model.predict(x_train)\n",
        "y_test_pred = best_knn_model.predict(x_test)\n",
        "\n",
        "# Évaluation de la performance sur les ensembles d'entraînement et de test\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nPerformance du meilleur modèle (KNN) :\")\n",
        "print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI3iIHaNgH8s",
        "outputId": "e158682d-8d15-4563-e51d-a0c3f973be07"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Meilleurs paramètres trouvés :\n",
            "{'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
            "Meilleur score (RMSE) : 8.828439545650692\n",
            "\n",
            "Performance du meilleur modèle (KNN) :\n",
            "Ensemble d'entraînement - MAE: 0.05761212685613912 RMSE: 0.8356796417488699 R²: 0.9975417004090303\n",
            "Ensemble de test - MAE: 5.799537877193314 RMSE: 8.019308270461755 R²: 0.7504306365188695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Définition des hyperparamètres à optimiser\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'max_iter': [1000, 2000, 3000]\n",
        "}\n",
        "\n",
        "# Initialisation du modèle MLPRegressor\n",
        "ann_model = MLPRegressor(random_state=42)\n",
        "\n",
        "# Initialisation de GridSearchCV avec le modèle et les hyperparamètres à optimiser\n",
        "grid_search = GridSearchCV(estimator=ann_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Entraînement du modèle avec GridSearchCV\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs paramètres et du meilleur score\n",
        "print(\"Meilleurs paramètres trouvés :\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Meilleur score (RMSE) :\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "# Utilisation du meilleur modèle pour les prédictions\n",
        "best_ann_model = grid_search.best_estimator_\n",
        "y_train_pred = best_ann_model.predict(x_train)\n",
        "y_test_pred = best_ann_model.predict(x_test)\n",
        "\n",
        "# Évaluation de la performance sur les ensembles d'entraînement et de test\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nPerformance du meilleur modèle (ANN) :\")\n",
        "print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE5TINxigg0V",
        "outputId": "3e92290c-aa42-42bb-da27-98abe4b67a39"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
            "Meilleurs paramètres trouvés :\n",
            "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'max_iter': 1000, 'solver': 'lbfgs'}\n",
            "Meilleur score (RMSE) : 5.329970134686228\n",
            "\n",
            "Performance du meilleur modèle (ANN) :\n",
            "Ensemble d'entraînement - MAE: 3.1212420311733884 RMSE: 4.122948094244304 R²: 0.9401628501877297\n",
            "Ensemble de test - MAE: 4.107735645294853 RMSE: 5.607636256027113 R²: 0.8779670459616256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Définition des hyperparamètres à optimiser\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'epsilon': [0.01, 0.1, 0.2],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Initialisation du modèle SVR\n",
        "svr_model = SVR()\n",
        "\n",
        "# Initialisation de GridSearchCV avec le modèle et les hyperparamètres à optimiser\n",
        "grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Entraînement du modèle avec GridSearchCV\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs paramètres et du meilleur score\n",
        "print(\"Meilleurs paramètres trouvés :\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Meilleur score (RMSE) :\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "# Utilisation du meilleur modèle pour les prédictions\n",
        "best_svr_model = grid_search.best_estimator_\n",
        "y_train_pred = best_svr_model.predict(x_train)\n",
        "y_test_pred = best_svr_model.predict(x_test)\n",
        "\n",
        "# Évaluation de la performance sur les ensembles d'entraînement et de test\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nPerformance du meilleur modèle (SVR) :\")\n",
        "print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlH3nTbhgxD6",
        "outputId": "8018613a-61c5-4683-8ede-b5448b93678d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "Meilleurs paramètres trouvés :\n",
            "{'C': 10, 'epsilon': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "Meilleur score (RMSE) : 7.15474955373382\n",
            "\n",
            "Performance du meilleur modèle (SVR) :\n",
            "Ensemble d'entraînement - MAE: 4.514153144883461 RMSE: 6.444977867549461 R²: 0.8537829475404597\n",
            "Ensemble de test - MAE: 5.2800072101265965 RMSE: 6.974031618303627 R²: 0.8112507309989592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Définition des hyperparamètres à optimiser\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Initialisation du modèle RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialisation de GridSearchCV avec le modèle et les hyperparamètres à optimiser\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Entraînement du modèle avec GridSearchCV\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs paramètres et du meilleur score\n",
        "print(\"Meilleurs paramètres trouvés :\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Meilleur score (RMSE) :\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "# Utilisation du meilleur modèle pour les prédictions\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_train_pred = best_rf_model.predict(x_train)\n",
        "y_test_pred = best_rf_model.predict(x_test)\n",
        "\n",
        "# Évaluation de la performance sur les ensembles d'entraînement et de test\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nPerformance du meilleur modèle (Random Forest) :\")\n",
        "print(\"Ensemble d'entraînement - MAE:\", mae_train, \"RMSE:\", rmse_train, \"R²:\", r2_train)\n",
        "print(\"Ensemble de test - MAE:\", mae_test, \"RMSE:\", rmse_test, \"R²:\", r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7NdD__Eg2rX",
        "outputId": "5b2aba84-e3ef-4e11-fff3-7704435c22cb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meilleurs paramètres trouvés :\n",
            "{'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "Meilleur score (RMSE) : 5.107448336945112\n",
            "\n",
            "Performance du meilleur modèle (Random Forest) :\n",
            "Ensemble d'entraînement - MAE: 1.2680047385934499 RMSE: 1.9133885157756012 R²: 0.9871127133007888\n",
            "Ensemble de test - MAE: 3.798832559049369 RMSE: 5.583038315940937 R²: 0.8790352948761324\n"
          ]
        }
      ]
    }
  ]
}